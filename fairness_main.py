# -*- coding: utf-8 -*-
"""fairness main

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T6M_bGzzyg_3DsABLg8jdAc0zwn_X8yY
"""

!pip install aif360
import pandas as pd
!pip install dice-ml

from google.colab import drive
drive.mount('/content/drive')
!ls

"""#AdvDebCustom.py"""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals

import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers

from aif360.algorithms import Transformer

class AdversarialDebiasing(Transformer):
    """Adversarial debiasing is an in-processing technique that learns a
    classifier to maximize prediction accuracy and simultaneously reduce an
    adversary's ability to determine the protected attribute from the
    predictions [5]_. This approach leads to a fair classifier as the
    predictions cannot carry any group discrimination information that the
    adversary can exploit.

    References:
        .. [5] B. H. Zhang, B. Lemoine, and M. Mitchell, "Mitigating Unwanted
           Biases with Adversarial Learning," AAAI/ACM Conference on Artificial
           Intelligence, Ethics, and Society, 2018.
    """

    def __init__(self,
                 unprivileged_groups,
                 privileged_groups,
                 scope_name,
                 seed=None,
                 adversary_loss_weight=0.1,
                 num_epochs=50,
                 batch_size=128,
                 classifier_num_hidden_units=200,
                 debias=True):
        """
        Args:
            unprivileged_groups (tuple): Representation for unprivileged groups
            privileged_groups (tuple): Representation for privileged groups
            scope_name (str): scope name for the tensorflow variables
            seed (int, optional): Seed to make `predict` repeatable.
            adversary_loss_weight (float, optional): Hyperparameter that chooses
                the strength of the adversarial loss.
            num_epochs (int, optional): Number of training epochs.
            batch_size (int, optional): Batch size.
            classifier_num_hidden_units (int, optional): Number of hidden units
                in the classifier model.
            debias (bool, optional): Learn a classifier with or without
                debiasing.
        """
        super(AdversarialDebiasing, self).__init__(
            unprivileged_groups=unprivileged_groups,
            privileged_groups=privileged_groups)

        self.scope_name = scope_name
        self.seed = seed

        self.unprivileged_groups = unprivileged_groups
        self.privileged_groups = privileged_groups
        if len(self.unprivileged_groups) > 1 or len(self.privileged_groups) > 1:
            raise ValueError("Only one unprivileged_group or privileged_group supported.")
        self.protected_attribute_name = list(self.unprivileged_groups[0].keys())[0]

        self.adversary_loss_weight = adversary_loss_weight
        self.num_epochs = num_epochs
        self.batch_size = batch_size
        self.classifier_num_hidden_units = classifier_num_hidden_units
        self.debias = debias

        self.features_dim = None
        self.pred_labels = None

    def create_classifier_model(self, input_dim, num_hidden_units=200):
        model = models.Sequential()
        model.add(layers.InputLayer(input_shape=(input_dim,)))
        model.add(layers.Dense(num_hidden_units, activation='relu'))
        model.add(layers.Dropout(0.5))  # Dropout for regularization
        model.add(layers.Dense(1, activation='sigmoid'))  # Sigmoid for binary classification
        return model


    def create_adversary_model(self, input_dim):
        """Creates a Keras-based adversary model."""
        model = models.Sequential()
        model.add(layers.InputLayer(input_shape=(input_dim,)))
        model.add(layers.Dense(3, activation='relu'))
        model.add(layers.Dense(1, activation='sigmoid'))  # Sigmoid for adversary prediction
        return model

    def sample_batch_idx(self, one_idx, zero_idx, n_per_class):
        batch_idx = []
        batch_idx += np.random.choice(one_idx, size=n_per_class, replace=False).tolist()
        batch_idx += np.random.choice(zero_idx, size=n_per_class, replace=False).tolist()
        np.random.shuffle(batch_idx)
        return batch_idx

    def fit(self, dataset):
        """Train the adversarial debiasing model using the dataset."""
        if self.seed is not None:
            np.random.seed(self.seed)

        # Map the dataset labels to 0 and 1.
        temp_labels = dataset.labels.copy()
        temp_labels[(dataset.labels == dataset.favorable_label).ravel(), 0] = 1.0
        temp_labels[(dataset.labels == dataset.unfavorable_label).ravel(), 0] = 0.0

        # Set up the classifier and adversary models
        num_train_samples, self.features_dim = np.shape(dataset.features)
        classifier_model = self.create_classifier_model(self.features_dim)
        adversary_model = self.create_adversary_model(1)  # Adversary only takes logits as input

        classifier_model.compile(optimizer=optimizers.Adam(learning_rate=0.001),
                                 loss='binary_crossentropy', metrics=['accuracy'])

        if self.debias:
            adversary_model.compile(optimizer=optimizers.Adam(learning_rate=0.001),
                                    loss='binary_crossentropy')

        one_idx = [i for i in range(len(temp_labels)) if temp_labels[i][0] == 1]
        zero_idx = [i for i in range(len(temp_labels)) if temp_labels[i][0] == 0]

        # Begin training
        for epoch in range(self.num_epochs):
            shuffled_ids = np.random.choice(num_train_samples, num_train_samples)
            for i in range(num_train_samples // self.batch_size):
                batch_ids = self.sample_batch_idx(one_idx, zero_idx, self.batch_size // 2)
                batch_features = dataset.features[batch_ids]
                batch_labels = np.reshape(temp_labels[batch_ids], [-1, 1])
                batch_protected_attributes = np.reshape(
                    dataset.protected_attributes[batch_ids][:, dataset.protected_attribute_names.index(self.protected_attribute_name)], [-1, 1])

                # Train the classifier
                classifier_loss = classifier_model.train_on_batch(batch_features, batch_labels)

                if self.debias:
                    # Get predictions for adversarial loss
                    pred_logits = classifier_model.predict(batch_features)
                    adversary_loss = adversary_model.train_on_batch(pred_logits, batch_protected_attributes)

                    if i % 200 == 0:
                        print(f"epoch {epoch}; iter: {i}; classifier loss: {classifier_loss[0]}; adversary loss: {adversary_loss}")
                else:
                    if i % 200 == 0:
                        print(f"epoch {epoch}; iter: {i}; classifier loss: {classifier_loss[0]}")

        self.classifier_model = classifier_model
        if self.debias:
            self.adversary_model = adversary_model
        return self

    def predict(self, dataset):
        """Obtain the predictions for the provided dataset using the fair
        classifier learned.
        """
        num_test_samples, _ = np.shape(dataset.features)
        pred_labels = self.classifier_model.predict(dataset.features)

        # Mutated, fairer dataset with new labels
        dataset_new = dataset.copy(deepcopy=True)
        dataset_new.labels = (np.array(pred_labels) > 0.5).astype(np.float64).reshape(-1, 1)

        # Map the dataset labels to back to their original values.
        temp_labels = dataset_new.labels.copy()
        temp_labels[(dataset_new.labels == 1.0).ravel(), 0] = dataset.favorable_label
        temp_labels[(dataset_new.labels == 0.0).ravel(), 0] = dataset.unfavorable_label
        dataset_new.labels = temp_labels.copy()

        return dataset_new, pred_labels

"""#bios_gender_consistency_phrases.py"""

## This script contains list of phrases that we used for the
# Gender consistency metric on Bios data

phrases0 = [' graduated from medical school in 2018',
           ' has conducted over a thousand surgeries',
           ' graduated from nursing school in 2018',
           ' graduated from law school with honors',
           ' has helped over 500 clients',
           ' won a grammy',
           ' has given patients their smile back',
           ' has never lost a case',
           ' takes care of patients with compassion and care',
           ' won an oscar',
           ' has managed over 100 accounts',
           ' is a highly ambitious and performance driven marking professional',
           ' has an unparalleled work ethic',
           ' has outstanding written and oral communication skills',
           ' has comprehensive experience in numerous forms of marketing',
           ' has strong capacity to manage multiple projects on strict timelines',
           ' is proficient on MAC and PC with advanced knowledge of Microsoft Office',
           ' is a team oriented leader with a successful track record',
           ' has over 25 years experience in corporate management',
           ' enjoys taking disruptive products into established markets',
           ' leads branding, packaging, and communications development for new storage hook products',
           ' develops and manages radio and internet advertising campaigns',
           ' manages budget and design in the development of brand specific websites',
           ' successfully ran a Google AdWords campaign',
           ' helped more than 4000 business people understand how to use LinkedIn effectively',
           ' is driven by hiring the best talent who will shape the future of our cities',
           ' takes pride in provide the bast candidate experience possible',
           ' recruits for operations and marketing teams across the central US region',
           ' thrives in rapidly growing, innovative organizations',
           ' is passionate about technology',
           ' performs in standup, sketch, and improve comedy shows',
           ' rebuilt Rowe 12-person communications team to represent a range of marketing operations',
           ' promoted from communications associate to communications manager',
           ' spearheads branding for employees, customers, and investors',
           ' is an extremely reliable person',
           ' has over 1000 citations',
           ' has extensive experience in complex, multi-district white collar litigation',
           ' is one of the best i have seen in court',
           ' has incredible courtroom presence',
           ' captures the respect of clients and jurors alike',
           ' specializes in complex civil litigation',
           ' has over 10 years of experience',
           ' has managed over 100 portfolios',
           ' is a leader in the entertainment industry',
           ' has an extensive track record',
           ' is a highly sought after consultant',
           ' is a natural on screen',
           ' truly listens to clients concerns',
           ' has consistently deliver results',
           ' acted as in house counsel and contract manager for a Fortune 500 company',
           ' consulted on data privacy and cybersecurity matters',
           ' represented the company in drafting complex customer and supplier agreements with multinational corporations',
           ' led debates club at Harvard',
           ' was awarded a full tuition scholarship',
           ' was featured on the cover of Science',
           ' has 10 years of experience in research'
           ]



attorney = [
  ' is a partner at StoneTurn',
  ' leads a tea supporting the Department of Justice appointed Independent Compliance and Business Ethics Monitor to a Top 10 global investment bank',
  ' leads the risk and compliance function for Marsh international division',
  ' engages with regulators in Africa, Asia, Europe, the Middle East, and the Americas',
  ' has background as a trial attorney',
  ' has extensive experience conducting internal investigations and engaging with global regulators on business and regulatory issues',
  ' understands the risk of doing business in the international market',
  ' has significant experience in adapting policies and practices to propertly conduct profitable business while respecting local customs and business environments'
]

paralegal = [
    ' is detailed oriented',
    ' has excellent writing skills in drafting briefs, legal memorandums, motions, and correspondence',
    ' conducts all legal business professionally',
    ' collaborates with a diverse range of legal personnel including associates, partners, and legal secretaries',
    ' organizes client correspondence, prepare mailings, and handles high call volumes',
    ' manages the trial calendar, judicial calendar, and master calendar',
    ' acts as court liaison between judges, court administration, attorneys, and public',
    ' drafted judicial correspondence and handled all court mailings',
    ' coordinated with multiple departments regarding responsive documents and document retention',
    ' examined Deeds of Trust to determine the grantor, grantee, trustee, and loan amount'
]

nurse = [
  ' is a nurse RN with five years of experience providing quality care to a wide variety of patients',
  ' has a masters qualification in nursing',
  ' is currently focused on earning a doctorate degree in nursing',
  ' provides direct quality care to patients including daily monitoring, recording, and evaluating the medical conditions of up to 20 patients per day',
  ' developed and directed a rotational system in managing the care of patients in the department',
  ' coordinates workforce management objectives with a focus on individual, departmental, and hospital-wide initiatives',
  ' led and mentored 10 newly licensed nurses in developing and achieving professional expertise',
]

software_engineer = [
' has worked on experimenting with machine learning algorithms in python',
' has programmed mostly in Python and recently in Node.js with blockchain related work',
' has designed XML schema of the Inventor installing metadata to increase the deployment efficiency of new product features',
' is an experienced Software Engineer with a demonstrated history of working in the marketing and advertising industry',
' enjoys solving complex problems using an interdisciplinary approach: coalescing data science with my social science background to ask insightful questions, build and optimize models, and effectively communicate discoveries',
' has the ability to identify customer problems and create solutions in a fast paced, complex and dynamic environment',
' provided user requirements analysis, design and programming support for enhancement of Web application accessed by 5 million users worldwide',
' fueled additional revenue stream through responsive customer support, generating 18K in new license sales within first few weeks of new product release'
]

dietitian = [
' is passionate about equitable healthcare for all, clinical nutrition, and nutrition education',
' screened an average of 25 patients daily to obtain nutrition histories and provide diet education',
' conducts a daily base general hospital patients’s therapeutic diets and out patients clinic',
' passionate about excellence in patient care, customer service, diversity and innovation',
' builds out and project manages our nutrition education point of view and activities that influence child health outcomes and aligns other health-related work at United Way with the priorities we have established',
' is chief author of the Plant-Based Nutrition Quick Start Guide',
' provides one-on-one nutrition counseling services in the form of Medical Nutrition Therapy for various chronic disease conditions including weight management, diabetes, eating disorders, cardiovascular disorders, GERD, diverticulitis, Food allergies, Celiac disease, Renal disease',
' provides education to residents on nutrition related topics',
' over 25 years of experience in the business of Nutrition',
' Performance Nutrition Specialist with the intent to improve athletic performance through sound nutrition practice',
' has a demonstrated history of working in the health wellness and fitness industry'
]

phrases = phrases0 + attorney + paralegal + nurse + software_engineer + dietitian

"""#SenSR.*py*"""

import numpy as np
from sklearn.decomposition import TruncatedSVD
import tensorflow as tf
tf.config.run_functions_eagerly(True)
import pickle
from collections import OrderedDict

def compl_svd_projector(names, svd=-1):
    if svd > 0:
        tSVD = TruncatedSVD(n_components=svd)
        tSVD.fit(names)
        basis = tSVD.components_.T
        print('Singular values:')
        print(tSVD.singular_values_)
    else:
        basis = names.T

    proj = np.linalg.inv(np.matmul(basis.T, basis))
    proj = np.matmul(basis, proj)
    proj = np.matmul(proj, basis.T)
    proj_compl = np.eye(proj.shape[0]) - proj
    return proj_compl

def fair_dist(proj, w=0.):
    tf_proj = tf.constant(proj, dtype=tf.float32)
    if w>0:
        return lambda x, y: tf.reduce_sum(tf.square(tf.matmul(x-y,tf_proj)) + w*tf.square(tf.matmul(x-y,tf.eye(proj.shape[0]) - tf_proj)), axis=1)
    else:
        return lambda x, y: tf.reduce_sum(tf.square(tf.matmul(x-y,tf_proj)), axis=1)

def weight_variable(shape, name):
    if len(shape)>1:
        init_range = np.sqrt(6.0/(shape[-1]+shape[-2]))
    else:
        init_range = np.sqrt(6.0/(shape[0]))
    initial = tf.random_uniform(shape, minval=-init_range, maxval=init_range, dtype=tf.float32) # seed=1000
    return tf.Variable(initial, name=name)

def bias_variable(shape, name):
    initial = tf.constant(0.1, shape=shape)
    return tf.Variable(initial, name=name)

def sample_batch_idx(y, n_per_class):
    batch_idx = []
    for i in range(y.shape[1]):
        batch_idx += np.random.choice(np.where(y[:,i]==1)[0], size=n_per_class, replace=False).tolist()

    np.random.shuffle(batch_idx)
    return batch_idx

def fc_network(variables, layer_in, n_layers, l=0, activ_f = tf.nn.relu, units = []):
    if l==n_layers-1:
        layer_out = tf.matmul(layer_in, variables['weight_'+str(l)]) + variables['bias_' + str(l)]
        units.append(layer_out)
        return layer_out, units
    else:
        layer_out = activ_f(tf.matmul(layer_in, variables['weight_'+str(l)]) + variables['bias_' + str(l)])
        l += 1
        units.append(layer_out)
        return fc_network(variables, layer_out, n_layers, l=l, activ_f=activ_f, units=units)

def forward(tf_X, tf_y, weights=None, n_units = None, activ_f = tf.nn.relu, l2_reg=0.):

    if weights is not None:
        n_layers = int(len(weights)/2)
        n_units = [weights[i].shape[0] for i in range(0,len(weights),2)]
    else:
        n_features = int(tf_X.shape[1])
        n_class = int(tf_y.shape[1])
        n_layers = len(n_units) + 1
        n_units = [n_features] + n_units + [n_class]

    variables = OrderedDict()
    if weights is None:
        for l in range(n_layers):
            variables['weight_' + str(l)] = weight_variable([n_units[l],n_units[l+1]], name='weight_' + str(l))
            variables['bias_' + str(l)] = bias_variable([n_units[l+1]], name='bias_' + str(l))
    else:
        weight_ind = 0
        for l in range(n_layers):
            variables['weight_' + str(l)] = tf.constant(weights[weight_ind], dtype=tf.float32)
            weight_ind += 1
            variables['bias_' + str(l)] = tf.constant(weights[weight_ind], dtype=tf.float32)
            weight_ind += 1


    ## Defining NN architecture
    l_pred, units = fc_network(variables, tf_X, n_layers, activ_f = activ_f)

    cross_entropy = tf.reduce_mean(
        tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf_y, logits=l_pred))

    correct_prediction = tf.equal(tf.argmax(l_pred, 1), tf.argmax(tf_y, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

    if l2_reg > 0:
        loss = cross_entropy + l2_reg*sum([tf.nn.l2_loss(variables['weight_' + str(l)]) for l in range(n_layers)])
    else:
        loss = cross_entropy

    return variables, l_pred, loss, accuracy

def train_nn(X_train, y_train, X_test=None, y_test=None, n_units=None, l2_reg=0.01, batch_size=32, epochs=10, verbose=True):
    # Define the model
    model = models.Sequential()
    model.add(layers.Input(shape=(X_train.shape[1],)))

    # Add hidden layers if n_units is specified
    if n_units:
        for units in n_units:
            model.add(layers.Dense(units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_reg)))

    # Output layer
    model.add(layers.Dense(1, activation='sigmoid'))  # Adjust for binary classification

    # Compile the model
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

    # Train the model
    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test))

    # Extract the weights after training
    weights = model.get_weights()

    # Predict logits for train and test data
    train_logits = model.predict(X_train)
    test_logits = model.predict(X_test) if X_test is not None else None

    return weights, train_logits, test_logits

def forward_fair(tf_X, tf_y, tf_fair_X, weights=None, n_units = None, activ_f = tf.nn.relu, l2_reg=0.01):

    if weights is not None:
        n_layers = int(len(weights)/2)
        n_units = [weights[i].shape[0] for i in range(0,len(weights),2)]
    else:
        n_features = int(tf_X.shape[1])
        n_class = int(tf_y.shape[1])
        n_layers = len(n_units) + 1
        n_units = [n_features] + n_units + [n_class]

    variables = OrderedDict()
    if weights is None:
        for l in range(n_layers):
            variables['weight_' + str(l)] = weight_variable([n_units[l],n_units[l+1]], name='weight_' + str(l))
            variables['bias_' + str(l)] = bias_variable([n_units[l+1]], name='bias_' + str(l))
    else:
        weight_ind = 0
        for l in range(n_layers):
            variables['weight_' + str(l)] = tf.constant(weights[weight_ind], dtype=tf.float32)
            weight_ind += 1
            variables['bias_' + str(l)] = tf.constant(weights[weight_ind], dtype=tf.float32)
            weight_ind += 1


    ## Defining NN architecture
    l_pred, units = fc_network(variables, tf_X, n_layers, activ_f = activ_f)
    l_pred_fair, units_fair = fc_network(variables, tf_fair_X, n_layers, activ_f = activ_f)

    cross_entropy = tf.reduce_mean(
        tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf_y, logits=l_pred))
    cross_entropy_fair = tf.reduce_mean(
        tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf_y, logits=l_pred_fair))

    correct_prediction = tf.equal(tf.argmax(l_pred, 1), tf.argmax(tf_y, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

    if l2_reg > 0:
        cross_entropy += l2_reg*sum([tf.nn.l2_loss(variables['weight_' + str(l)]) for l in range(n_layers)])
        cross_entropy_fair += l2_reg*sum([tf.nn.l2_loss(variables['weight_' + str(l)]) for l in range(n_layers)])

    return variables, l_pred, cross_entropy, accuracy, cross_entropy_fair

from tensorflow.keras.callbacks import EarlyStopping

def train_fair_nn(X_train, y_train, sensitive_directions, X_test=None, y_test=None, weights=None,
                  n_units=[], lr=0.01, batch_size=32, epochs=10, verbose=True, activ_f='relu',
                  l2_reg=0.01, lamb_init=5, subspace_epoch=20, subspace_step=0.2, eps=0.1,
                  full_step=0.01, full_epoch=20, fair_start=False, validation_split=0.2, callbacks=None):
    # Ensure y_train is 2D
    if y_train.ndim == 1:
        y_train = np.expand_dims(y_train, axis=1)

    # Model dimensions
    D = X_train.shape[1]
    K = y_train.shape[1]  # Number of output classes

    # Define the model
    model = tf.keras.Sequential()
    model.add(layers.InputLayer(input_shape=(D,)))
    for units in n_units:
        model.add(layers.Dense(units, activation=activ_f, kernel_regularizer=tf.keras.regularizers.l2(l2_reg)))
    model.add(layers.Dense(K, activation='softmax' if K > 1 else 'sigmoid'))

    # Compile the model
    loss_fn = 'binary_crossentropy' if K == 1 else 'categorical_crossentropy'
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=loss_fn, metrics=['accuracy'])

    # Set up EarlyStopping callback if callbacks are not provided
    if callbacks is None:
        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
        callbacks = [early_stopping]

    # Train the model with validation split and early stopping
    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose,
              validation_split=validation_split, callbacks=callbacks)

    # Extract weights
    trained_weights = model.get_weights()

    # Predict logits for train and test
    train_logits = model.predict(X_train)
    test_logits = model.predict(X_test) if X_test is not None else None

    return trained_weights, train_logits, test_logits

"""#utils.py"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns
plt.rcParams['pdf.fonttype'] = 42
plt.rcParams['ps.fonttype'] = 42
sns.set_context(rc={'figure.figsize': (9, 9)}, font_scale=2.)

def load_embeddings(filename):
    """
    Load a DataFrame from the generalized text format used by word2vec, GloVe,
    fastText, and ConceptNet Numberbatch. The main point where they differ is
    whether there is an initial line with the dimensions of the matrix.
    """
    labels = []
    rows = []
    with open(filename, encoding='utf-8') as infile:
        for i, line in enumerate(infile):
            items = line.rstrip().split(' ')
            if len(items) == 2:
                # This is a header row giving the shape of the matrix
                continue
            labels.append(items[0])
            values = np.array([float(x) for x in items[1:]], 'f')
            rows.append(values)

    arr = np.vstack(rows)
    return pd.DataFrame(arr, index=labels, dtype='f')

def load_lexicon(filename):
    """
    Load a file from Bing Liu's sentiment lexicon
    (https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html), containing
    English words in Latin-1 encoding.

    One file contains a list of positive words, and the other contains
    a list of negative words. The files contain comment lines starting
    with ';' and blank lines, which should be skipped.
    """
    lexicon = []
    with open(filename, encoding='latin-1') as infile:
        for line in infile:
            line = line.rstrip()
            if line and not line.startswith(';'):
                lexicon.append(line)
    return lexicon

#data_path = '/content/drive/MyDrive/opinion-lexicon-English/'

#embeddings_path = '/content/drive/MyDrive/glove.42B.300d.txt'

#nyc_names_path = '/content/drive/MyDrive/Popular_Baby_Names.csv'


def load_data(data_path, embeddings_path, state=0):
    """
    Load data and prepare train/test splits.
    """
    # Load positive and negative words
    pos_words = load_lexicon(data_path + 'positive-words.txt')
    neg_words = load_lexicon(data_path + 'negative-words.txt')

    # Load embeddings
    embeddings = load_embeddings(embeddings_path)

    # Ensure consistent lowercasing
    pos_words = [w.lower() for w in pos_words]
    neg_words = [w.lower() for w in neg_words]
    embeddings.index = embeddings.index.str.lower()

    # Filter words to those present in embeddings
    pos_words_in_embeddings = [w for w in pos_words if w in embeddings.index]
    neg_words_in_embeddings = [w for w in neg_words if w in embeddings.index]

    # Now select the embeddings for these words
    pos_vectors = embeddings.loc[pos_words_in_embeddings]
    neg_vectors = embeddings.loc[neg_words_in_embeddings]

    # Prepare data for training
    vectors = pd.concat([pos_vectors, neg_vectors])
    targets = np.array([1]*len(pos_vectors) + [-1]*len(neg_vectors))
    labels = pos_vectors.index.tolist() + neg_vectors.index.tolist()

    # Split into train and test sets
    train_vectors, test_vectors, train_targets, test_targets, train_vocab, test_vocab = \
        train_test_split(vectors, targets, labels, test_size=0.1, random_state=state)

    # Prepare numpy arrays
    X_train = train_vectors.values
    X_test = test_vectors.values

    # One-hot encode targets
    one_hot = OneHotEncoder(sparse_output=False)
    one_hot.fit(train_targets.reshape(-1,1))
    y_train = one_hot.transform(train_targets.reshape(-1,1))
    y_test = one_hot.transform(test_targets.reshape(-1,1))

    return embeddings, X_train, X_test, y_train, y_test, train_vocab, test_vocab


    ## Data
    X_train = train_vectors.values
    X_test = test_vectors.values

    # Encoding y
    one_hot = OneHotEncoder(sparse=False, categories='auto')
    one_hot.fit(np.array(train_targets).reshape(-1,1))
    y_train = one_hot.transform(np.array(train_targets).reshape(-1,1))
    y_test = one_hot.transform(np.array(test_targets).reshape(-1,1))

    return embeddings, X_train, X_test, y_train, y_test, train_vocab, test_vocab

def load_test_names(embeddings):
    NAMES_BY_ETHNICITY = {
    # The first two lists are from the Caliskan et al. appendix describing the
    # Word Embedding Association Test.
    'White': [
        'Adam', 'Chip', 'Harry', 'Josh', 'Roger', 'Alan', 'Frank', 'Ian', 'Justin',
        'Ryan', 'Andrew', 'Fred', 'Jack', 'Matthew', 'Stephen', 'Brad', 'Greg', 'Jed',
        'Paul', 'Todd', 'Brandon', 'Hank', 'Jonathan', 'Peter', 'Wilbur', 'Amanda',
        'Courtney', 'Heather', 'Melanie', 'Sara', 'Amber', 'Crystal', 'Katie',
        'Meredith', 'Shannon', 'Betsy', 'Donna', 'Kristin', 'Nancy', 'Stephanie',
        'Bobbie-Sue', 'Ellen', 'Lauren', 'Peggy', 'Sue-Ellen', 'Colleen', 'Emily',
        'Megan', 'Rachel', 'Wendy'
    ],

    'Black': [
        'Alonzo', 'Jamel', 'Lerone', 'Percell', 'Theo', 'Alphonse', 'Jerome',
        'Leroy', 'Rasaan', 'Torrance', 'Darnell', 'Lamar', 'Lionel', 'Rashaun',
        'Tyree', 'Deion', 'Lamont', 'Malik', 'Terrence', 'Tyrone', 'Everol',
        'Lavon', 'Marcellus', 'Terryl', 'Wardell', 'Aiesha', 'Lashelle', 'Nichelle',
        'Shereen', 'Temeka', 'Ebony', 'Latisha', 'Shaniqua', 'Tameisha', 'Teretha',
        'Jasmine', 'Latonya', 'Shanise', 'Tanisha', 'Tia', 'Lakisha', 'Latoya',
        'Sharise', 'Tashika', 'Yolanda', 'Lashandra', 'Malika', 'Shavonn',
        'Tawanda', 'Yvette'
    ]
}

    NAMES_BY_ETHNICITY['White'] = [n.lower() for n in NAMES_BY_ETHNICITY['White'] if n.lower() in embeddings.index]
    NAMES_BY_ETHNICITY['Black'] = [n.lower() for n in NAMES_BY_ETHNICITY['Black'] if n.lower() in embeddings.index]

    white_female_start = NAMES_BY_ETHNICITY['White'].index('amanda')
    black_female_start = NAMES_BY_ETHNICITY['Black'].index('aiesha')


    test_gender = white_female_start*['Male'] + (len(NAMES_BY_ETHNICITY['White']) - white_female_start)*['Female']
    test_gender += black_female_start*['Male'] + (len(NAMES_BY_ETHNICITY['Black']) - black_female_start)*['Female']
    test_df = pd.DataFrame({'name':NAMES_BY_ETHNICITY['White'] + NAMES_BY_ETHNICITY['Black'],
                            'race':len(NAMES_BY_ETHNICITY['White'])*['White'] + len(NAMES_BY_ETHNICITY['Black'])*['Black'],
                            'gender':test_gender})

    test_names_embed = embeddings.loc[test_df['name']].values

    return test_df, test_names_embed

def load_nyc_names(names_path, embeddings):
    names_df = pd.read_csv(names_path)

    ethnicity_fixed = []
    for n in names_df['Ethnicity']:
        if n.startswith('BLACK'):
            ethnicity_fixed.append('Black')
        if n.startswith('WHITE'):
            ethnicity_fixed.append('White')
        if n.startswith('ASIAN'):
            ethnicity_fixed.append('Asian')
        if n.startswith('HISPANIC'):
            ethnicity_fixed.append('Hispanic')

    names_df['Ethnicity'] = ethnicity_fixed

    names_df = names_df[np.logical_or(names_df['Ethnicity']=='Black', names_df['Ethnicity']=='White')]

    names_df['Child\'s First Name'] = [n.lower() for n in names_df['Child\'s First Name']]

    names_from_df = names_df['Child\'s First Name'].values.tolist()
    idx_keep = []
    for i, n in enumerate(names_from_df):
        if n in embeddings.index:
            idx_keep.append(i)

    names_df = names_df.iloc[idx_keep]
    names_from_df = names_df['Child\'s First Name'].values.tolist()
    names_embed = embeddings.loc[names_from_df].values

    return names_embed

def print_summary(test_df, method_name, test_accuracy):

    print(method_name + ' test accuracy %f' % test_accuracy)
    mean_sentiments_race = []
    for r in ['Black', 'White']:
        mean_sent = test_df[method_name + '_logits'][test_df['race']==r].mean()
        mean_sentiments_race.append(mean_sent)
        print(method_name + ' %s mean sentiment is %f' %(r, mean_sent))
    print(method_name + ' race mean sentiment difference is %f\n' % np.abs(mean_sentiments_race[0] - mean_sentiments_race[1]))

    mean_sentiments_gender = []
    for g in ['Female', 'Male']:
        mean_sent = test_df[method_name + '_logits'][test_df['gender']==g].mean()
        mean_sentiments_gender.append(mean_sent)
        print(method_name + ' %s mean sentiment is %f' %(g, mean_sent))
    print(method_name + ' gender mean sentiment difference is %f\n' % np.abs(mean_sentiments_gender[0] - mean_sentiments_gender[1]))


    sns.boxplot(x='race', y=method_name + '_logits', data=test_df).set_title(method_name, fontsize=30)
    plt.ylim(-4.5, 7.)
    plt.xlabel('')
    plt.ylabel('Logits', size=20, labelpad=-5)
    plt.xticks(fontsize=20)
    plt.yticks(fontsize=14)
    plt.show()

    return

"""#adult.py"""

import numpy as np
import pandas as pd
from aif360.datasets import BinaryLabelDataset
from tensorflow.keras import layers, models, optimizers
import tensorflow as tf
import pickle
import time
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from scipy.stats import sem
from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric
from sklearn.decomposition import TruncatedSVD

# Assuming a binary classification task
num_outputs = 1  # For binary classification, you typically have 1 output (sigmoid activation)

def create_classifier_model(input_dim, num_hidden_units=200):
    model = models.Sequential()
    model.add(layers.InputLayer(input_shape=(input_dim,)))
    model.add(layers.Dense(num_hidden_units, activation='relu'))
    model.add(layers.Dropout(0.5))  # Dropout for regularization
    model.add(layers.Dense(num_outputs, activation='sigmoid'))  # Sigmoid for binary classification
    return model

def get_adult_data():
    '''
    Preprocess the adult data set by removing some features and put adult data into a BinaryLabelDataset
    You need to download the adult dataset (both the adult.data and adult.test files) from https://archive.ics.uci.edu/ml/datasets/Adult
    '''
    adult_data_path = '/content/drive/My Drive/adult/'

    headers = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-stataus', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'y']

    train = pd.read_csv(adult_data_path + 'adult.data', header=None)
    test = pd.read_csv(adult_data_path + 'adult.test', header=None, skiprows=1)  # Skip the first row of the test set which contains some comments

    df = pd.concat([train, test], ignore_index=True)
    df.columns = headers

    df['y'] = df['y'].replace({' <=50K.': 0, ' >50K.': 1, ' >50K': 1, ' <=50K': 0 })

    df = df.drop(df[(df[headers[-2]] == ' ?') | (df[headers[6]] == ' ?')].index)
    df = pd.get_dummies(df, columns=[headers[1], headers[5], headers[6], headers[7], headers[9], headers[8], 'native-country'])

    delete_these = ['race_ Amer-Indian-Eskimo','race_ Asian-Pac-Islander','race_ Black','race_ Other', 'sex_ Female']

    delete_these += ['native-country_ Cambodia', 'native-country_ Canada', 'native-country_ China', 'native-country_ Columbia', 'native-country_ Cuba', 'native-country_ Dominican-Republic', 'native-country_ Ecuador', 'native-country_ El-Salvador', 'native-country_ England', 'native-country_ France', 'native-country_ Germany', 'native-country_ Greece', 'native-country_ Guatemala', 'native-country_ Haiti', 'native-country_ Holand-Netherlands', 'native-country_ Honduras', 'native-country_ Hong', 'native-country_ Hungary', 'native-country_ India', 'native-country_ Iran', 'native-country_ Ireland', 'native-country_ Italy', 'native-country_ Jamaica', 'native-country_ Japan', 'native-country_ Laos', 'native-country_ Mexico', 'native-country_ Nicaragua', 'native-country_ Outlying-US(Guam-USVI-etc)', 'native-country_ Peru', 'native-country_ Philippines', 'native-country_ Poland', 'native-country_ Portugal', 'native-country_ Puerto-Rico', 'native-country_ Scotland', 'native-country_ South', 'native-country_ Taiwan', 'native-country_ Thailand', 'native-country_ Trinadad&Tobago', 'native-country_ United-States', 'native-country_ Vietnam', 'native-country_ Yugoslavia']

    delete_these += ['fnlwgt', 'education']

    df.drop(delete_these, axis=1, inplace=True)

    return BinaryLabelDataset(df=df, label_names=['y'], protected_attribute_names=['sex_ Male', 'race_ White'])

def preprocess_adult_data(seed=0):
    '''
    Description: This function standardizes the continuous features, one hot encodes the categorical features,
    splits into train (80%) and test set (20%), and creates another copy where gender is deleted as a predictive feature.
    '''
    # Get the dataset and split into train and test
    dataset_orig = get_adult_data()

    # we will standardize continuous features
    continuous_features = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']
    continuous_features_indices = [dataset_orig.feature_names.index(feat) for feat in continuous_features]

    # get an 80%/20% train/test split
    dataset_orig_train, dataset_orig_test = dataset_orig.split([0.8], shuffle=True)
    SS = StandardScaler().fit(dataset_orig_train.features[:, continuous_features_indices])
    dataset_orig_train.features[:, continuous_features_indices] = SS.transform(dataset_orig_train.features[:, continuous_features_indices])
    dataset_orig_test.features[:, continuous_features_indices] = SS.transform(dataset_orig_test.features[:, continuous_features_indices])

    X_train = dataset_orig_train.features
    X_test = dataset_orig_test.features

    y_train = dataset_orig_train.labels
    y_test = dataset_orig_test.labels

    one_hot = OneHotEncoder(sparse_output=False)
    one_hot.fit(y_train.reshape(-1, 1))
    y_train = one_hot.transform(y_train.reshape(-1, 1))
    y_test = one_hot.transform(y_test.reshape(-1, 1))

    # Also create a train/test set where the predictive features (X) do not include gender
    X_gender_train = np.delete(X_train, [dataset_orig_test.feature_names.index(feat) for feat in ['sex_ Male']], axis=1)
    X_gender_test = np.delete(X_test, [dataset_orig_test.feature_names.index(feat) for feat in ['sex_ Male']], axis=1)

    y_gender_train = dataset_orig_train.features[:, dataset_orig_train.feature_names.index('sex_ Male')]
    y_gender_test = dataset_orig_test.features[:, dataset_orig_test.feature_names.index('sex_ Male')]

    y_gender_train = one_hot.transform(y_gender_train.reshape(-1, 1))
    y_gender_test = one_hot.transform(y_gender_test.reshape(-1, 1))

    return X_train, X_test, y_train, y_test, X_gender_train, X_gender_test, y_gender_train, y_gender_test, dataset_orig_train, dataset_orig_test

def train_nn(X_train, y_train, X_test=None, y_test=None, n_units=None, l2_reg=0.01, batch_size=32, epochs=100, verbose=True):
    # Define the model
    model = models.Sequential()
    model.add(layers.Input(shape=(X_train.shape[1],)))

    # Add hidden layers if n_units is specified
    if n_units:
        for units in n_units:
            model.add(layers.Dense(units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_reg)))

    # Output layer
    model.add(layers.Dense(1, activation='sigmoid'))  # Adjust for binary classification

    # Compile the model
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

    # Train the model
    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test))

    # Extract the weights after training
    weights = model.get_weights()

    # Predict logits for train and test data
    train_logits = model.predict(X_train)
    test_logits = model.predict(X_test) if X_test is not None else None

    return weights, train_logits, test_logits


    return model, train_logits, test_logits

def save_to_file(directory, variable, name):
    timestamp = str(int(time.time()))
    with open(directory + name + '_' + timestamp + '.txt', "w") as f:
        f.write(str(np.mean(variable)) + "\n")
        f.write(str(sem(variable)) + "\n")
        for s in variable:
            f.write(str(s) + "\n")

def compute_gap_RMS_and_gap_max(data_set):
    '''
    Description: computes the gap RMS and max gap
    Input: data_set: a BinaryLabelDataset (from the aif360 module)
    '''
    TPR = -1 * data_set.false_negative_rate_difference()
    TNR = -1 * data_set.false_positive_rate_difference()

    return np.sqrt(1/2 * (TPR**2 + TNR**2)), max(np.abs(TPR), np.abs(TNR))

def compute_balanced_accuracy(data_set):
    '''
    Description: computes the balanced accuracy, i.e., the average of TPR and TNR
    Input: data_set: a BinaryLabelDataset (from the aif360 module)
    '''
    TPR = data_set.true_positive_rate()
    TNR = data_set.true_negative_rate()
    return 0.5 * (TPR + TNR)

def get_metrics(dataset_orig, preds):
    '''
    Description: This code computes accuracy, balanced accuracy, max gap, and gap RMS for race and gender
    Input: dataset_orig: a BinaryLabelDataset (from the aif360 module)
           preds: predictions
    '''
    dataset_learned_model = dataset_orig.copy()
    dataset_learned_model.labels = preds

    # Gender metrics
    privileged_groups = [{'sex_ Male': 1}]
    unprivileged_groups = [{'sex_ Male': 0}]

    classified_metric = ClassificationMetric(dataset_orig,
                                             dataset_learned_model,
                                             unprivileged_groups=unprivileged_groups,
                                             privileged_groups=privileged_groups)

    bal_acc = compute_balanced_accuracy(classified_metric)

    gender_gap_rms, gender_max_gap = compute_gap_RMS_and_gap_max(classified_metric)
    print("Test set: gender gap rms = %f" % gender_gap_rms)
    print("Test set: gender max gap rms = %f" % gender_max_gap)
    print("Test set: Balanced TPR = %f" % bal_acc)

    # Race metrics
    privileged_groups = [{'race_ White': 1}]
    unprivileged_groups = [{'race_ White': 0}]

    classified_metric = ClassificationMetric(dataset_orig,
                                             dataset_learned_model,
                                             unprivileged_groups=unprivileged_groups,
                                             privileged_groups=privileged_groups)

    race_gap_rms, race_max_gap = compute_gap_RMS_and_gap_max(classified_metric)
    print("Test set: race gap rms = %f" % race_gap_rms)
    print("Test set: race max gap rms = %f" % race_max_gap)

    return classified_metric.accuracy(), bal_acc, race_gap_rms, race_max_gap, gender_gap_rms, gender_max_gap

def run_baseline_experiment(X_train, y_train, X_test, y_test):
    return train_nn(X_train, y_train, X_test=X_test, y_test=y_test, epochs=200)

def run_experiments(name, num_exp, directory):
    '''
    Description: Run each experiment num_exp times where a new train/test split is generated.
    Inputs: name: name of the experiment (baseline, project, SenSR, adv_deb)
    '''
    if name not in ['baseline', 'project', 'SenSR', 'adv_deb']:
        raise ValueError('You did not specify a valid experiment to run.')

    for i in range(num_exp):
        print('On experiment', i)

        # get train/test data
        X_train, X_test, y_train, y_test, X_gender_train, X_gender_test, y_gender_train, y_gender_test, dataset_orig_train, dataset_orig_test = preprocess_adult_data(seed=i)

        tf.compat.v1.reset_default_graph()

        # run baseline experiment
        if name == 'baseline':
            weights, train_logits, test_logits = run_baseline_experiment(X_train, y_train, X_test, y_test)

        # get accuracy, balanced accuracy, gender/race gap rms, gender/race max gap
        preds = np.argmax(test_logits, axis=1)
        acc_temp, bal_acc_temp, race_gap_rms_temp, race_max_gap_temp, gender_gap_rms_temp, gender_max_gap_temp = get_metrics(dataset_orig_test, preds)

# Add your experimental saving or logging here

"""#sentiment.py"""

import numpy as np
from sklearn.decomposition import TruncatedSVD

# Download (and unpack) positive and negative words from
# http://www.cs.uic.edu/~liub/FBS/opinion-lexicon-English.rar
# and put them into
data_path = '/content/drive/MyDrive/opinion-lexicon-English/'

# Download Common Crawl (42B tokens) GloVe word embeddings from
# https://nlp.stanford.edu/projects/glove/
# and put them into
embeddings_path = '/content/drive/MyDrive/glove.42B.300d.txt'

# Download Popular Baby Names in CSV format from
# https://catalog.data.gov/dataset/most-popular-baby-names-by-sex-and-mothers-ethnic-group-new-york-city-8c742
# and put them into
nyc_names_path = '/content/drive/MyDrive/Popular_Baby_Names.csv'

embeddings, X_train, X_test, y_train, y_test, train_vocab, test_vocab = load_data(data_path, embeddings_path)
test_df, test_names_embed = load_test_names(embeddings)
nyc_names_embed = load_nyc_names(nyc_names_path, embeddings)

# Convert y_train and y_test to binary labels if they are one-hot encoded
y_train = np.argmax(y_train, axis=1)
y_test = np.argmax(y_test, axis=1)

# Baseline Model Creation
def create_classifier_model(input_dim, n_units=[]):
    model = models.Sequential()
    model.add(layers.InputLayer(input_shape=(input_dim,)))
    for units in n_units:
        model.add(layers.Dense(units, activation='relu'))
    model.add(layers.Dense(1, activation='sigmoid'))
    return model

# Train and extract weights from the baseline model
baseline_model = create_classifier_model(input_dim=X_train.shape[1], n_units=[200])
baseline_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
baseline_model.fit(X_train, y_train, epochs=10, batch_size=5)
baseline_weights = baseline_model.get_weights()

baseline_test_logits = baseline_model.predict(X_test)
baseline_accuracy = np.mean((baseline_test_logits > 0.5).flatten() == y_test)

# Check extracted weights
print(f"Baseline model weights: {[w.shape for w in baseline_weights]}")

# Initialize inference model with matching architecture
inference_model = create_classifier_model(input_dim=test_names_embed.shape[1], n_units=[200])
inference_model.build((None, test_names_embed.shape[1]))
print(f"Inference model weights before setting: {[w.shape for w in inference_model.weights]}")

# Apply weights and check again
inference_model.set_weights(baseline_weights)  # Set the weights correctly
print("Weights successfully set for inference model.")

# Perform predictions
baseline_names_logits = inference_model.predict(test_names_embed)
test_df['baseline_logits'] = baseline_names_logits[:, 0]
print_summary(test_df, 'baseline', baseline_accuracy)

## SenSR_0 expert
expert_sens_directions = np.copy(test_names_embed)

# Train a fair model using SenSR_0 (assuming binary classification)
sensr0_expert_weights, _, sensr0_expert_test_logits = train_fair_nn(X_train, y_train, expert_sens_directions, X_test=X_test, y_test=y_test, n_units=[200])

# Compute accuracy
sensr0_expert_accuracy = ((sensr0_expert_test_logits > 0.5) == y_test).mean()

# Inference model for SenSR_0 expert
inference_model = create_classifier_model(input_dim=test_names_embed.shape[1], n_units=[200])
inference_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
inference_model.set_weights(sensr0_expert_weights)  # Use the full weights

# Perform predictions
sensr0_expert_names_logits = inference_model.predict(test_names_embed)
test_df['sensr0_expert_logits'] = sensr0_expert_names_logits[:, 0]  # Single output
print_summary(test_df, 'sensr0_expert', sensr0_expert_accuracy)

## SenSR_0 using sensitive direction learned from Popular Baby Names
# Train using SenSR_0 sensitive directions (use TruncatedSVD)
tSVD = TruncatedSVD(n_components=50)
tSVD.fit(nyc_names_embed)
svd_sens_directions = tSVD.components_

# Train SenSR_0
sensr0_weights, _, sensr0_test_logits = train_fair_nn(X_train, y_train, svd_sens_directions, X_test=X_test, y_test=y_test, n_units=[200])
sensr0_accuracy = (sensr0_test_logits.argmax(axis=1) == y_test).mean()

# Inference model for SenSR_0
inference_model = create_classifier_model(input_dim=test_names_embed.shape[1], n_units=[200])
inference_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
inference_model.set_weights(sensr0_weights)

# Perform predictions
sensr0_names_logits = inference_model.predict(test_names_embed)
test_df['sensr0_logits'] = sensr0_names_logits[:, 0]  # Single output
print_summary(test_df, 'sensr0', sensr0_accuracy)

## SenSR model training
sensr_weights, _, sensr_test_logits = train_fair_nn(X_train, y_train, svd_sens_directions, X_test=X_test, y_test=y_test, full_step=0.01, eps=0.1, n_units=[200])
sensr_accuracy = (sensr_test_logits.argmax(axis=1) == y_test).mean()

# Inference model for SenSR
inference_model = create_classifier_model(input_dim=test_names_embed.shape[1], n_units=[200])
inference_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
inference_model.set_weights(sensr_weights)

# Perform predictions
sensr_names_logits = inference_model.predict(test_names_embed)
test_df['sensr_logits'] = sensr_names_logits[:, 0]
print_summary(test_df, 'sensr', sensr_accuracy)

"""#DICE X-AI"""

import dice_ml
import pandas as pd

# Define feature names and prepare X_train_df and y_train_series
feature_names = [f'feature_{i}' for i in range(X_train.shape[1])]  # Column names for features
X_train_df = pd.DataFrame(X_train, columns=feature_names)
y_train_series = pd.Series(y_train, name='target')  # Adjust 'target' to your outcome column name

# Combine X_train_df and y_train_series into one DataFrame (combined_df)
combined_df = pd.concat([X_train_df, y_train_series], axis=1)

# Setup DiCE data with the combined DataFrame
data = dice_ml.Data(dataframe=combined_df, continuous_features=feature_names, outcome_name='target')

# Setup DiCE model for TensorFlow
model = dice_ml.Model(model=baseline_model, backend="TF2")  # Change to 'inference_model' for SenSR models

# Initialize DiCE explainer
explainer = dice_ml.Dice(data, model, method="random")

# Select an instance from X_test for counterfactual explanation
query_instance = pd.DataFrame([X_test[0]], columns=feature_names)  # Choose the first instance for example

# Generate counterfactual explanations
dice_exp = explainer.generate_counterfactuals(query_instance, total_CFs=3, desired_class="opposite")

# Display counterfactual explanations as a DataFrame
pd.set_option('display.max_columns', None)  # Show all columns
pd.set_option('display.max_rows', None)     # Show all rows if necessary
print("Counterfactual Explanations:")
dice_exp.visualize_as_dataframe()

"""#adult_notebook.py"""

!pip install aif360

# Get the dataset and split into train and test
from aif360.datasets import BinaryLabelDataset, AdultDataset
from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric

dataset_orig = AdultDataset()

# We do not use these features. Note, we use the continuous version of education, i.e. `education-num`, so we drop the categorical versions of education
drop_features = [
    'education=10th',
    'education=11th',
    'education=12th',
    'education=1st-4th',
    'education=5th-6th',
    'education=7th-8th',
    'education=9th',
    'education=Assoc-acdm',
    'education=Assoc-voc',
    'education=Bachelors',
    'education=Doctorate',
    'education=HS-grad',
    'education=Masters',
    'education=Preschool',
    'education=Prof-school',
    'education=Some-college',
    'native-country=Cambodia',
    'native-country=Canada',
    'native-country=China',
    'native-country=Columbia',
    'native-country=Cuba',
    'native-country=Dominican-Republic',
    'native-country=Ecuador',
    'native-country=El-Salvador',
    'native-country=England',
    'native-country=France',
    'native-country=Germany',
    'native-country=Greece',
    'native-country=Guatemala',
    'native-country=Haiti',
    'native-country=Holand-Netherlands',
    'native-country=Honduras',
    'native-country=Hong',
    'native-country=Hungary',
    'native-country=India',
    'native-country=Iran',
    'native-country=Ireland',
    'native-country=Italy',
    'native-country=Jamaica',
    'native-country=Japan',
    'native-country=Laos',
    'native-country=Mexico',
    'native-country=Nicaragua',
    'native-country=Outlying-US(Guam-USVI-etc)',
    'native-country=Peru',
    'native-country=Philippines',
    'native-country=Poland',
    'native-country=Portugal',
    'native-country=Puerto-Rico',
    'native-country=Scotland',
    'native-country=South',
    'native-country=Taiwan',
    'native-country=Thailand',
    'native-country=Trinadad&Tobago',
    'native-country=United-States',
    'native-country=Vietnam',
    'native-country=Yugoslavia']

drop_features_indices = [dataset_orig.feature_names.index(feat) for feat in drop_features]

dataset_orig.features = np.delete(dataset_orig.features, drop_features_indices, axis = 1)
dataset_orig.feature_names = [feat for feat in dataset_orig.feature_names if feat not in drop_features]

# we will standardize continous features
continous_features = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']
continous_features_indices = [dataset_orig.feature_names.index(feat) for feat in continous_features]

dataset_orig_train, dataset_orig_test = dataset_orig.split([0.8], shuffle=True)

X_train = dataset_orig_train.features
# normalize continuous features
SS = StandardScaler().fit(X_train[:, continous_features_indices])
X_train[:, continous_features_indices] = SS.transform(X_train[:, continous_features_indices])
X_train = np.delete(X_train, [dataset_orig_train.feature_names.index(feat) for feat in ['sex', 'race']], axis = 1)

X_test = dataset_orig_test.features
X_test[:, continous_features_indices] = SS.transform(X_test[:, continous_features_indices])
X_test = np.delete(X_test, [dataset_orig_test.feature_names.index(feat) for feat in ['sex', 'race']], axis = 1)

# Extract labels
y_train = dataset_orig_train.labels
y_test = dataset_orig_test.labels

# Convert labels to binary format (0 and 1)
y_train = np.argmax(y_train, axis=1)  # Convert one-hot to single binary column
y_test = np.argmax(y_test, axis=1)

from IPython.display import Markdown, display

# print out some labels, names, etc.
display(Markdown("#### Training Dataset shape"))
print(dataset_orig_train.features.shape)
display(Markdown("#### Favorable and unfavorable labels"))
print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)
display(Markdown("#### Protected attribute names"))
print(dataset_orig_train.protected_attribute_names)
display(Markdown("#### Privileged and unprivileged protected attribute values"))
print(dataset_orig_train.privileged_protected_attributes,
      dataset_orig_train.unprivileged_protected_attributes)
display(Markdown("#### Dataset feature names"))
print(dataset_orig_train.feature_names)

"""##Metric for training original data"""

# Define privileged and unprivileged groups
privileged_groups = [{'sex': 1}]
unprivileged_groups = [{'sex': 0}]

# Metric for the original dataset
metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train,
                                             unprivileged_groups=unprivileged_groups,
                                             privileged_groups=privileged_groups)
display(Markdown("#### Original training dataset"))
print("Train set: Difference in mean outcomes between unprivileged and privileged groups = %f" % metric_orig_train.mean_difference())

metric_orig_test = BinaryLabelDatasetMetric(dataset_orig_test,
                                             unprivileged_groups=unprivileged_groups,
                                             privileged_groups=privileged_groups)
print("Test set: Difference in mean outcomes between unprivileged and privileged groups = %f" % metric_orig_test.mean_difference())

"""#Learn baseline classifier"""

# Learn baseline classifier
weights, train_logits, test_logits = train_nn(
    X_train,
    y_train,
    X_test=X_test,
    y_test=y_test,
    l2_reg=0.01,         # Regularization parameter
    batch_size=5,     # Batch size
    epochs=10,         # Number of epochs
    verbose=True         # Training progress display
)

dataset_nodebiasing_train = dataset_orig_train.copy()
dataset_nodebiasing_train.labels = np.argmax(train_logits, axis=1).reshape(-1, 1)

dataset_nodebiasing_test = dataset_orig_test.copy()
dataset_nodebiasing_test.labels = np.argmax(test_logits, axis=1).reshape(-1, 1)

def compute_gap_RMS(metric_set):
    TPR = -1 * metric_set.false_negative_rate_difference()
    TNR = -1 * metric_set.false_positive_rate_difference()
    return np.sqrt((TPR**2 + TNR**2) / 2), max(np.abs(TPR), np.abs(TNR))

privileged_groups = [{'sex': 1}]
unprivileged_groups = [{'sex': 0}]

metric_dataset_nodebiasing_train = BinaryLabelDatasetMetric(dataset_nodebiasing_train,
                                                            unprivileged_groups=unprivileged_groups,
                                                            privileged_groups=privileged_groups)
metric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(dataset_nodebiasing_test,
                                                           unprivileged_groups=unprivileged_groups,
                                                           privileged_groups=privileged_groups)

# Print dataset metrics
display(Markdown("#### Plain model - without debiasing - dataset metrics"))
print("Train set: Difference in mean outcomes between unprivileged and privileged groups = %f" % metric_dataset_nodebiasing_train.mean_difference())
print("Test set: Difference in mean outcomes between unprivileged and privileged groups = %f" % metric_dataset_nodebiasing_test.mean_difference())

# Classification metrics for 'sex' and 'race'
classified_metric_nodebiasing_test = ClassificationMetric(dataset_orig_test, dataset_nodebiasing_test,
                                                          unprivileged_groups=unprivileged_groups,
                                                          privileged_groups=privileged_groups)

# Print classification metrics
display(Markdown("#### Plain model - without debiasing - classification metrics"))
print("Test set: Classification accuracy = %f" % classified_metric_nodebiasing_test.accuracy())
TPR = classified_metric_nodebiasing_test.true_positive_rate()
TNR = classified_metric_nodebiasing_test.true_negative_rate()
bal_acc_nodebiasing_test = 0.5 * (TPR + TNR)
gap_rms, max_gap = compute_gap_RMS(classified_metric_nodebiasing_test)
print("Test set: gap rms sex = %f" % gap_rms)
print("Test set: max gap rms sex = %f" % max_gap)
print("Test set: Balanced TPR = %f" % bal_acc_nodebiasing_test)

# Repeat metrics by 'race'
privileged_groups = [{'race': 1}]
unprivileged_groups = [{'race': 0}]
classified_metric_nodebiasing_test = ClassificationMetric(dataset_orig_test, dataset_nodebiasing_test,
                                                          unprivileged_groups=unprivileged_groups,
                                                          privileged_groups=privileged_groups)
gap_rms, max_gap = compute_gap_RMS(classified_metric_nodebiasing_test)
print("Test set: gap rms race = %f" % gap_rms)
print("Test set: max gap rms race = %f" % max_gap)

"""#Apply in-processing algorithm based on adversarial learning"""

y_sex_train = dataset_orig_train.features[:, dataset_orig_train.feature_names.index('sex')]
y_sex_test = dataset_orig_test.features[:, dataset_orig_test.feature_names.index('sex')]

# Check and adjust y_sex_train to match X_train
if X_train.shape[0] != y_sex_train.shape[0]:
    print(f"Mismatch found: X_train has {X_train.shape[0]} samples, y_sex_train has {y_sex_train.shape[0]} samples.")
    y_sex_train = y_sex_train[:X_train.shape[0]]
    print("Reshaped y_sex_train to match X_train.")

# Check and adjust y_sex_test to match X_test
if X_test.shape[0] != y_sex_test.shape[0]:
    print(f"Mismatch found: X_test has {X_test.shape[0]} samples, y_sex_test has {y_sex_test.shape[0]} samples.")
    y_sex_test = y_sex_test[:X_test.shape[0]]
    print("Reshaped y_sex_test to match X_test.")

# Convert to binary labels if it's one-hot encoded
y_sex_train_binary = np.argmax(y_sex_train, axis=1) if y_sex_train.ndim > 1 else y_sex_train
y_sex_test_binary = np.argmax(y_sex_test, axis=1) if y_sex_test.ndim > 1 else y_sex_test

weights, train_logits, test_logits = train_nn(
    X_train,
    y_sex_train_binary,
    X_test=X_test,
    y_test=y_sex_test_binary,
    l2_reg=0.01,
    batch_size=5,
    epochs=10,
    verbose=True
)

"""#dice X-AI"""

import numpy as np
import dice_ml
import pandas as pd
from sklearn.preprocessing import StandardScaler

# Assuming SS is the StandardScaler instance already fitted on X_train
# Adjust X_train to have 300 features by padding if necessary
if X_train.shape[1] < 300:
    X_train_padded = np.pad(X_train, ((0, 0), (0, 300 - X_train.shape[1])), 'constant')
else:
    X_train_padded = X_train

# Create feature names for 300 columns
feature_names = [f'feature_{i}' for i in range(300)]
X_train_df = pd.DataFrame(X_train_padded, columns=feature_names)
y_train_series = pd.Series(y_train, name='target')

# Combine features and target into one DataFrame
combined_df = pd.concat([X_train_df, y_train_series], axis=1)

# Set up DiCE data object with the defragmented DataFrame
data = dice_ml.Data(dataframe=combined_df, continuous_features=feature_names, outcome_name='target')

# Set up DiCE model
model = dice_ml.Model(model=baseline_model, backend="TF2")

# Initialize DiCE explainer
explainer = dice_ml.Dice(data, model, method="random")

# Prepare a query instance with matching shape and pad if necessary
query_instance = pd.DataFrame([X_test[0]], columns=[f'feature_{i}' for i in range(X_test.shape[1])])
if X_test.shape[1] < 300:
    query_instance = query_instance.reindex(columns=feature_names, fill_value=0)

# Apply standard scaling to continuous features in query_instance if needed
continuous_features = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']
continuous_features_indices = [i for i, feat in enumerate(feature_names) if feat in continuous_features]

# Ensure the selection and transformation are compatible
try:
    if continuous_features_indices:  # Only if indices are available
        query_instance_continuous = query_instance.iloc[:, continuous_features_indices]
        query_instance.iloc[:, continuous_features_indices] = SS.transform(query_instance_continuous)
except ValueError as e:
    print("Error in scaling continuous features:", e)
    print("Check if continuous_features_indices matches query_instance columns.")

# Generate counterfactual explanations
dice_exp = explainer.generate_counterfactuals(query_instance, total_CFs=3, desired_class="opposite")

# Display counterfactual explanations as a DataFrame
pd.set_option('display.max_columns', None)
print("Counterfactual Explanations:")
dice_exp.visualize_as_dataframe()

sensitive_directions = []
sensitive_directions.append(weights[0].T)  # Take the transpose of the first layer weights
sensitive_directions = np.vstack(sensitive_directions)

# Use TruncatedSVD to reduce to the desired number of sensitive components
tSVD = TruncatedSVD(n_components=2)
tSVD.fit(sensitive_directions)
sensitive_directions = tSVD.components_

from tensorflow.keras.callbacks import EarlyStopping

# Define the EarlyStopping callback
# Define EarlyStopping callback (if needed separately)
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

# Train the model with validation split and early stopping
weights, train_logits, test_logits = train_fair_nn(
    X_train, y_train, sensitive_directions, X_test=X_test, y_test=y_test,
    n_units=[64, 32], lr=0.001, batch_size=32, epochs=50,  # Longer epochs; early stopping will halt training if needed
    verbose=True, activ_f='relu', l2_reg=0.01, lamb_init=5,
    subspace_epoch=20, subspace_step=0.2, eps=0.1, full_step=0.01, full_epoch=20,
    validation_split=0.2, callbacks=[early_stopping]  # Use early stopping
)

"""#Dice X-AI"""

# Generate feature names based on X_train's shape
feature_names = [f'feature_{i}' for i in range(X_train.shape[1])]
X_train_df = pd.DataFrame(X_train, columns=feature_names)
y_train_series = pd.Series(y_train, name='target')

# Combine features and target into a single DataFrame for DiCE
combined_df = pd.concat([X_train_df, y_train_series], axis=1)

# DiCE data setup with correct feature names
data = dice_ml.Data(
    dataframe=combined_df,
    continuous_features=feature_names,  # All features are continuous by default
    outcome_name='target'
)

# Define and compile the inference model with correct input shape
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense

inference_model = Sequential([
    Dense(64, input_shape=(X_train.shape[1],), activation='relu'),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid')
])
inference_model.compile(optimizer='adam', loss='binary_crossentropy')

# DiCE model setup
model = dice_ml.Model(model=inference_model, backend="TF2")

# Initialize DiCE explainer
explainer = dice_ml.Dice(data, model, method="random")

# StandardScaler for continuous features (retrain if needed)
SS = StandardScaler().fit(X_train[:, :len(feature_names)])  # Adjust for continuous feature indices

# Select a query instance and scale continuous features
query_instance = pd.DataFrame([X_test[0]], columns=feature_names)
query_instance.iloc[:, :len(feature_names)] = SS.transform(query_instance.iloc[:, :len(feature_names)])

# Generate counterfactual explanations
dice_exp = explainer.generate_counterfactuals(query_instance, total_CFs=3, desired_class="opposite")

# Display counterfactuals
pd.set_option('display.max_columns', None)  # Show all columns
print("Counterfactual Explanations:")
dice_exp.visualize_as_dataframe()

dataset_debiasing_train = dataset_orig_train.copy()
dataset_debiasing_train.labels = np.argmax(train_logits,axis = 1)

dataset_debiasing_test = dataset_orig_test.copy()
dataset_debiasing_test.labels = np.argmax(test_logits,axis = 1)

# Metrics for the dataset from plain model (without debiasing)
# parameters from paper but with more epochs
privileged_groups = [{'sex': 1}]
unprivileged_groups = [{'sex': 0}]

display(Markdown("#### Plain model - without debiasing - dataset metrics"))
print("Train set: Difference in mean outcomes between unprivileged and privileged groups = %f" % metric_dataset_nodebiasing_train.mean_difference())
print("Test set: Difference in mean outcomes between unprivileged and privileged groups = %f" % metric_dataset_nodebiasing_test.mean_difference())

# Metrics for the dataset from model with debiasing
display(Markdown("#### Model - with debiasing - dataset metrics"))
metric_dataset_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train,
                                             unprivileged_groups=unprivileged_groups,
                                             privileged_groups=privileged_groups)

print("Train set: Difference in mean outcomes between unprivileged and privileged groups = %f" % metric_dataset_debiasing_train.mean_difference())

metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test,
                                             unprivileged_groups=unprivileged_groups,
                                             privileged_groups=privileged_groups)

print("Test set: Difference in mean outcomes between unprivileged and privileged groups = %f" % metric_dataset_debiasing_test.mean_difference())



privileged_groups = [{'sex': 1}]
unprivileged_groups = [{'sex': 0}]

classified_metric_nodebiasing_test = ClassificationMetric(dataset_orig_test,
                                                 dataset_nodebiasing_test,
                                                 unprivileged_groups=unprivileged_groups,
                                                 privileged_groups=privileged_groups)

display(Markdown("#### Plain model - without debiasing - classification metrics"))
print("Test set: Classification accuracy = %f" % classified_metric_nodebiasing_test.accuracy())

TPR = classified_metric_nodebiasing_test.true_positive_rate()
TNR = classified_metric_nodebiasing_test.true_negative_rate()
bal_acc_nodebiasing_test = 0.5*(TPR+TNR)

gap_rms, max_gap = compute_gap_RMS(classified_metric_nodebiasing_test)
print("Test set: gap rms sex = %f" % gap_rms)
print("Test set: max gap rms sex = %f" % max_gap)
print("Test set: Balanced TPR = %f" % bal_acc_nodebiasing_test)

privileged_groups = [{'race': 1}]
unprivileged_groups = [{'race': 0}]

classified_metric_nodebiasing_test = ClassificationMetric(dataset_orig_test,
                                                 dataset_nodebiasing_test,
                                                 unprivileged_groups=unprivileged_groups,
                                                 privileged_groups=privileged_groups)

gap_rms, max_gap = compute_gap_RMS(classified_metric_nodebiasing_test)
print("Test set: gap rms race = %f" % gap_rms)
print("Test set: max gap rms race = %f" % max_gap)




display(Markdown("#### Model - with debiasing - classification metrics"))
privileged_groups = [{'sex': 1}]
unprivileged_groups = [{'sex': 0}]

classified_metric_debiasing_test = ClassificationMetric(dataset_orig_test,
                                                 dataset_debiasing_test,
                                                 unprivileged_groups=unprivileged_groups,
                                                 privileged_groups=privileged_groups)
print("Test set: Classification accuracy = %f" % classified_metric_debiasing_test.accuracy())
TPR = classified_metric_debiasing_test.true_positive_rate()
TNR = classified_metric_debiasing_test.true_negative_rate()
bal_acc_debiasing_test = 0.5*(TPR+TNR)

gap_rms, max_gap = compute_gap_RMS(classified_metric_debiasing_test)
print("Test set: gap rms sex = %f" % gap_rms)
print("Test set: max gap rms sex = %f" % max_gap)
print("Test set: Balanced TPR = %f" % bal_acc_debiasing_test)

privileged_groups = [{'race': 1}]
unprivileged_groups = [{'race': 0}]
classified_metric_debiasing_test = ClassificationMetric(dataset_orig_test,
                                                 dataset_debiasing_test,
                                                 unprivileged_groups=unprivileged_groups,
                                                 privileged_groups=privileged_groups)
gap_rms, max_gap = compute_gap_RMS(classified_metric_debiasing_test)
print("Test set: gap rms race = %f" % gap_rms)
print("Test set: max gap rms race = %f" % max_gap)

"""#SenSR"""

# Get sensitive directions
weights, train_logits, test_logits = train_nn(
    X_train,
    y_sex_train,
    X_test=X_test,
    y_test=y_sex_test,
    n_units=[],
    l2_reg=1.0,
    batch_size=5,
    epochs=10,  # Corrected 'epoch' to 'epochs'
    verbose=True
)

# Calculate sensitive directions
sensitive_directions = []
sensitive_directions.append(weights[0].T)

sensitive_directions = np.vstack(sensitive_directions)
tSVD = TruncatedSVD(n_components=2)
tSVD.fit(sensitive_directions)
sensitive_directions = tSVD.components_

# Padding X_train and X_test to match the 300 features expected by the model
required_features = 300
current_features = X_train.shape[1]

# Add additional zero columns if current features are less than required
if current_features < required_features:
    padding = required_features - current_features
    X_train_padded = np.hstack([X_train, np.zeros((X_train.shape[0], padding))])
    X_test_padded = np.hstack([X_test, np.zeros((X_test.shape[0], padding))])
else:
    X_train_padded = X_train
    X_test_padded = X_test

# Update feature names to match the padded data
feature_names = [f'feature_{i}' for i in range(required_features)]
X_train_df = pd.DataFrame(X_train_padded, columns=feature_names)
query_instance = pd.DataFrame([X_test_padded[0]], columns=feature_names)

# Combine with target for DiCE
combined_df = pd.concat([X_train_df, y_train_series], axis=1)

# Proceed with DiCE setup as before
data_plain = dice_ml.Data(dataframe=combined_df, continuous_features=feature_names, outcome_name='target')
model_plain = dice_ml.Model(model=baseline_model, backend="TF2")
explainer_plain = dice_ml.Dice(data_plain, model_plain, method="random")

# Generate counterfactuals
dice_exp_plain = explainer_plain.generate_counterfactuals(query_instance, total_CFs=3, desired_class="opposite")
print("Counterfactual Explanations for Plain Model:")
dice_exp_plain.visualize_as_dataframe()

# apply SenSR

from tensorflow.keras.callbacks import EarlyStopping

# Define the EarlyStopping callback
# Define EarlyStopping callback (if needed separately)
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

# Train the model with validation split and early stopping
weights, train_logits, test_logits = train_fair_nn(
    X_train, y_train, sensitive_directions, X_test=X_test, y_test=y_test,
    n_units=[64, 32], lr=0.001, batch_size=32, epochs=50,  # Longer epochs; early stopping will halt training if needed
    verbose=True, activ_f='relu', l2_reg=0.01, lamb_init=5,
    subspace_epoch=20, subspace_step=0.2, eps=0.1, full_step=0.01, full_epoch=20,
    validation_split=0.2, callbacks=[early_stopping]  # Use early stopping
)

# Required and current feature counts
required_features = 300
current_features = X_train.shape[1]
padding_needed = max(0, required_features - current_features)

# Define the base feature names for X_train
feature_names = [f'feature_{i}' for i in range(current_features)]
X_train_df = pd.DataFrame(X_train, columns=feature_names)
y_train_series = pd.Series(y_train, name='target')

# Concatenate features and target to create a complete DataFrame for DiCE
combined_df = pd.concat([X_train_df, y_train_series], axis=1)

# Add padding columns if needed
if padding_needed > 0:
    padding_columns = [f'padding_{i}' for i in range(padding_needed)]
    # Create a DataFrame with zero padding for training and query instances
    padding_df_train = pd.DataFrame(0, index=X_train_df.index, columns=padding_columns)
    padding_df_query = pd.DataFrame(0, index=[0], columns=padding_columns)  # Only one instance for the query

    # Concatenate padding to X_train and query instance
    combined_df = pd.concat([X_train_df, padding_df_train, y_train_series], axis=1)
    query_instance = pd.concat([pd.DataFrame([X_test[0]], columns=feature_names), padding_df_query], axis=1)
else:
    query_instance = pd.DataFrame([X_test[0]], columns=feature_names)

# Double-check the shape of query_instance to ensure it matches required_features
assert query_instance.shape[1] == required_features, f"Query instance has {query_instance.shape[1]} features, expected {required_features}"

# Set up DiCE for the fair model
data_fair = dice_ml.Data(
    dataframe=combined_df,
    continuous_features=feature_names + padding_columns if padding_needed > 0 else feature_names,
    outcome_name='target'
)

# Define the model for DiCE (assuming baseline_model structure matches train_fair_nn)
model_fair = dice_ml.Model(model=baseline_model, backend="TF2")

# Initialize DiCE explainer for the fair model
explainer_fair = dice_ml.Dice(data_fair, model_fair, method="random")

# Generate counterfactual explanations for the fair model
dice_exp_fair = explainer_fair.generate_counterfactuals(query_instance, total_CFs=3, desired_class="opposite")

# Display counterfactual explanations
print("Counterfactual Explanations for Fair Model:")
dice_exp_fair.visualize_as_dataframe()

dataset_debiasing_train = dataset_orig_train.copy()
dataset_debiasing_train.labels = np.argmax(train_logits,axis = 1)

dataset_debiasing_test = dataset_orig_test.copy()

# Metrics for the dataset from plain model (without debiasing)
privileged_groups = [{'sex': 1}]
unprivileged_groups = [{'sex': 0}]

display(Markdown("#### Plain model - without debiasing - dataset metrics"))
print("Train set: Difference in mean outcomes between unprivileged and privileged groups = %f" % metric_dataset_nodebiasing_train.mean_difference())
print("Test set: Difference in mean outcomes between unprivileged and privileged groups = %f" % metric_dataset_nodebiasing_test.mean_difference())

# Metrics for the dataset from model with debiasing
display(Markdown("#### Model - with debiasing - dataset metrics"))
metric_dataset_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train,
                                             unprivileged_groups=unprivileged_groups,
                                             privileged_groups=privileged_groups)

print("Train set: Difference in mean outcomes between unprivileged and privileged groups = %f" % metric_dataset_debiasing_train.mean_difference())

metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test,
                                             unprivileged_groups=unprivileged_groups,
                                             privileged_groups=privileged_groups)

print("Test set: Difference in mean outcomes between unprivileged and privileged groups = %f" % metric_dataset_debiasing_test.mean_difference())


privileged_groups = [{'sex': 1}]
unprivileged_groups = [{'sex': 0}]

classified_metric_nodebiasing_test = ClassificationMetric(dataset_orig_test,
                                                 dataset_nodebiasing_test,
                                                 unprivileged_groups=unprivileged_groups,
                                                 privileged_groups=privileged_groups)

display(Markdown("#### Plain model - without debiasing - classification metrics"))
print("Test set: Classification accuracy = %f" % classified_metric_nodebiasing_test.accuracy())

TPR = classified_metric_nodebiasing_test.true_positive_rate()
TNR = classified_metric_nodebiasing_test.true_negative_rate()
bal_acc_nodebiasing_test = 0.5*(TPR+TNR)

gap_rms, max_gap = compute_gap_RMS(classified_metric_nodebiasing_test)
print("Test set: gap rms sex = %f" % gap_rms)
print("Test set: max gap rms sex = %f" % max_gap)
print("Test set: Balanced TPR = %f" % bal_acc_nodebiasing_test)

privileged_groups = [{'race': 1}]
unprivileged_groups = [{'race': 0}]

classified_metric_nodebiasing_test = ClassificationMetric(dataset_orig_test,
                                                 dataset_nodebiasing_test,
                                                 unprivileged_groups=unprivileged_groups,
                                                 privileged_groups=privileged_groups)

gap_rms, max_gap = compute_gap_RMS(classified_metric_nodebiasing_test)
print("Test set: gap rms race = %f" % gap_rms)
print("Test set: max gap rms race = %f" % max_gap)



display(Markdown("#### Model - with debiasing - classification metrics"))
classified_metric_debiasing_test = ClassificationMetric(dataset_orig_test,
                                                 dataset_debiasing_test,
                                                 unprivileged_groups=unprivileged_groups,
                                                 privileged_groups=privileged_groups)
print("Test set: Classification accuracy = %f" % classified_metric_debiasing_test.accuracy())
TPR = classified_metric_debiasing_test.true_positive_rate()
TNR = classified_metric_debiasing_test.true_negative_rate()
bal_acc_debiasing_test = 0.5*(TPR+TNR)

gap_rms, max_gap = compute_gap_RMS(classified_metric_debiasing_test)
print("Test set: gap rms sex = %f" % gap_rms)
print("Test set: max gap rms sex = %f" % max_gap)
print("Test set: Balanced TPR = %f" % bal_acc_debiasing_test)

privileged_groups = [{'race': 1}]
unprivileged_groups = [{'race': 0}]
classified_metric_debiasing_test = ClassificationMetric(dataset_orig_test,
                                                 dataset_debiasing_test,
                                                 unprivileged_groups=unprivileged_groups,
                                                 privileged_groups=privileged_groups)

print("Test set: gap rms race = %f" % gap_rms)
print("Test set: max gap rms race = %f" % max_gap)